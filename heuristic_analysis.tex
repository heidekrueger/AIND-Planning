\documentclass{article}
\usepackage[utf8x]{inputenc}
\title{AIND Planning Project: Heuristic Analysis}
\author{Stefan Heidekr√ºger}


%\usepackage
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amstext}
%\usepackage{graphicx}
%\usepackage{xfrac}
\usepackage[left=1in, right=1in, top=1in, bottom=1in]{geometry}
%\usepackage{hyperref}
%\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
%\usepackage{dsfont}
%\usepackage{courier}
%\usepackage{color}
\usepackage{amsthm}
%\usepackage[super]{nth}
\renewcommand{\qed}{\unskip\nobreak\quad\qedsymbol} %fixes position of \qed
\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear,open={(},close={)}}
\usepackage{rotating}
\usepackage{enumitem}
\usepackage{slashbox}
\usepackage[]{nomencl}
\usepackage{comment}
\usepackage[gen]{eurosym}
\usepackage{caption}
\usepackage{chngcntr}

\usepackage{xargs}                      % Use more than one optional parameter in a new commands
\usepackage[pdftex,dvipsnames]{xcolor}  % Coloured text etc.

\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}

\newcommandx{\notsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
%\newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
\newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
\newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
%\newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}}

\usepackage{titlesec}
\setcounter{secnumdepth}{3}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\newcommand\inv[1]{#1^{-1}}
\newcommand\expect[2][]{\mathbb E_{#1}\left[#2 \right]}
\newcommand\card{\texttt{\#}}

%Define Theorem Environments
\theoremstyle{plain}
\newtheorem{thm}{Theorem}%[chapter]
\newtheorem{propos}[thm]{Proposition}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{definition}
\newtheorem{defn}{Definition}[]
\newtheorem{ass}{Assumption}[]
\theoremstyle{remark}
\newtheorem*{exmpl}{Example}
\newtheorem*{remark}{Remark}
\newtheorem*{remarks}{Remarks}


\begin{document}
\maketitle

In this analysis, we will compare and contrast different search algorithms and their performance on the project problems.

\paragraph{Optimal Plans for the Problems}

The optimal plan-lengths for Problems 1,2 and 3 are given by 6, 9 and 12, respectively. The (non-unique!) optimal plans for each problem are detailed in Table \ref{table-optimal-plans}.

\begin{table}[h]
\centering
\caption{Optimal Plans found for each of the problems.}
\label{table-optimal-plans}
	\begin{tabular}{l||l|l|l}
	Problem      & P1     & P2     & P3      \\ \hline
	Optimal Plan & \begin{tabular}[c]{@{}l@{}}Load(C1, P1, SFO)\\ Load(C2, P2, JFK)\\ Fly(P2, JFK, SFO)\\ Unload(C2, P2, SFO)\\ Fly(P1, SFO, JFK)\\ Unload(C1, P1, JFK)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Load(C1, P1, SFO)\\ Load(C2, P2, JFK)\\ Load(C3, P3, ATL)\\ Fly(P2, JFK, SFO)\\ Unload(C2, P2, SFO)\\ Fly(P1, SFO, JFK)\\ Unload(C1, P1, JFK)\\ Fly(P3, ATL, SFO)\\ Unload(C3, P3, SFO)\end{tabular} & \begin{tabular}[c]{@{}l@{}}Load(C1, P1, SFO)\\ Load(C2, P2, JFK)\\ Fly(P1, SFO, ATL)\\ Load(C3, P1, ATL)\\ Fly(P2, JFK, ORD)\\ Load(C4, P2, ORD)\\ Fly(P1, ATL, JFK)\\ Unload(C1, P1, JFK)\\ Fly(P2, ORD, SFO)\\ Unload(C2, P2, SFO)\\ Unload(C3, P1, JFK)\\ Unload(C4, P2, SFO)\end{tabular} \\ \hline
	Length       & 6     & 9         & 12                                                                     
	\end{tabular}
\end{table}





\paragraph{Comparison of non-heuristic search algorithms}

In this section we will compare the performance of the uninformed algorithms used, in particular Breadth First Search (BFS), Depth First Search (DFS) and Uniform Cost Search (UCS). In our analysis, we do not consider the performance of Breadth First Tree Search and Depth Limited Search, as these timed out on our software for Problems P2 and P3 (i.e. runtime over 10 minutes).

By design, BFS and UCS are guaranteed to always find an optimal solution to the problem (as long as a solution exists and the algorithm terminates, compare \citet[Ch. 3.4]{russell2009artificial}). In fact, each step in our plan is associated with a single cost unit, thus BFS and UCS are virtually equivalent in our case, except that UCS has a more "generous" policy towards extending the frontier. This fact explains that in practice, BFS expanded around 15\% - 30\% fewer nodes and performed somewhat faster than UCS (40ms vs 50ms for P1, 11.41 vs 14.59s for P2, 51.68 vs 63.25 seconds for P3).\footnote{For our experiments, we used a faster implementation of the FIFO-Queue in BFS than the one provided, compare \cite{fifoForumPost}.}

While depth first search, on the other hand has no guarantee to find an optimal solution, it was much faster than the other algorithms at the task of finding \emph{any} solutions. In fact, it found an optimal solution to P3 in $2.36$ seconds, i.e. less than $5\%$ of the runtime of BFS. Albeit the solutions found by DFS may be very suboptimal, checking weather a solution exists may sometimes be advantageous to waiting longer for the optimal solution. For detailed comparison of the result, see Tables \ref{table-performance1}, \ref{table-performance2} and \ref{table-performance 3}. 


\begin{table}[h]
\centering
\caption{Performance on Problem 1.}
\label{table-performance1}
\begin{tabular}{llrrrrr}
   & \multicolumn{1}{l|}{}                                           & Expansions & Goal Tests & New Nodes   & Time (s)      & Path Length \\ \hline
1  & \multicolumn{1}{l|}{breadth\_first\_search}                     & 43         & 56         & 180         & 0.04          & \textbf{6}  \\
2  & \multicolumn{1}{l|}{breadth\_first\_tree\_search}               & 1458       & 1459       & 5960        & 1.27          & \textbf{6}  \\
3  & \multicolumn{1}{l|}{depth\_first\_graph\_search}                & 21         & 22         & 84          & 0.02          & 20          \\
4  & \multicolumn{1}{l|}{depth\_limited\_search}                     & 101        & 271        & 414         & 0.12          & 50          \\
5  & \multicolumn{1}{l|}{uniform\_cost\_search}                      & 55         & 57         & 224         & 0.05          & \textbf{6}  \\
6  & \multicolumn{1}{l|}{recursive\_best\_first\_search, h1}   & 442        & 4230       & 17023       & 3.62          & \textbf{6}  \\
7  & \multicolumn{1}{l|}{greedy\_best\_first\_graph\_search, h1} & \textbf{7} & \textbf{9} & \textbf{28} & \textbf{0.01} & \textbf{6}  \\
8  & \multicolumn{1}{l|}{astar\_search, h\_1}                    & 55         & 57         & 224         & 0.04          & \textbf{6}  \\
9  & \multicolumn{1}{l|}{astar\_search, h\_ignore\_preconds}     & 41         & 43         & 170         & 0.03          & \textbf{6}  \\
10 & \multicolumn{1}{l|}{astar\_search, h\_pg\_levelsum}        & 11         & 13         & 50          & 1.00          & \textbf{6} 
\end{tabular}

\bigskip
\bigskip

\caption{Performance on Problem 2}
\label{table-performance2}
\begin{tabular}{ll|rrrrr}
   &                                            & \multicolumn{1}{l}{Expansions} & \multicolumn{1}{l}{Goal Tests} & \multicolumn{1}{l}{New Nodes} & \multicolumn{1}{l}{Time (s)} & \multicolumn{1}{l}{Path Length} \\ \cline{2-7} 
1  & breadth\_first\_search                     & 3343                           & 4609                           & 30509                         & 11.41                              & \textbf{9}                      \\
2  & breadth\_first\_tree\_search               & --                             & --                             & --                            & timed out                          & --                              \\
3  & depth\_first\_graph\_search                & 624                            & 625                            & 5602                          & 4.64                               & 619                             \\
4  & depth\_limited\_search                     & --                             & --                             & --                            & timed out                          & --                              \\
5  & uniform\_cost\_search                      & 4604                           & 4606                           & 41828                         & 14.59                              & 9                               \\
6  & recursive\_best\_first\_search, h1   & --                             & --                             & --                            & timed out                          & --                              \\
7  & greedy\_best\_first\_graph\_search, h1 & 454                            & 456                            & 4087                          & \textbf{1.37}                      & 19                              \\
8  & astar\_search, h1                    & 4604                           & 4606                           & 41828                         & 13.92                              & \textbf{9}                      \\
9  & astar\_search, h\_ignore\_preconds     & 1310                           & 1312                           & 11979                         & 4.02                               & \textbf{9}                      \\
10 & astar\_search, h\_pg\_levelsum         & \textbf{74}                    & \textbf{76}                    & \textbf{720}                  & 81.99                              & \textbf{9}                     
\end{tabular}

\bigskip
\bigskip

\caption{Performance on Problem 3}
\label{table-performance 3}
\begin{tabular}{ll|rrrrr}
   &                                        & \multicolumn{1}{l}{Expansions} & \multicolumn{1}{l}{Goal Tests} & \multicolumn{1}{l}{New Nodes} & \multicolumn{1}{l}{Time (s)} & \multicolumn{1}{l}{Path Length} \\ \hline
1  & breadth\_first\_search                 & 14663                          & 18098                          & 129631                        & 51.68                        & \textbf{12}                     \\
2  & breadth\_first\_tree\_search           & --                             & --                             & --                            & timed out                    & --                              \\
3  & depth\_first\_graph\_search            & 408                            & 409                            & 3364                          & \textbf{2.36}                & 392                             \\
4  & depth\_limited\_search                 & --                             & --                             & --                            & timed out                    & --                              \\
5  & uniform\_cost\_search                  & 16963                          & 16965                          & 149136                        & 63.25                        & \textbf{12}                     \\
6  & recursive\_best\_first\_search, h1     & --                             & --                             & --                            & timed out                    & --                              \\
7  & greedy\_best\_first\_graph\_search, h1 & 3773                           & 3775                           & 33127                         & 14.97                        & 30                              \\
8  & astar\_search, h1                      & 16963                          & 16965                          & 149136                        & 63.61                        & \textbf{12}                     \\
9  & astar\_search, h\_ignore\_preconds     & 4443                           & 4445                           & 39217                         & 17.77                        & \textbf{12}                     \\
10 & astar\_search, h\_pg\_levelsum         & \textbf{228}                   & \textbf{230}                   & \textbf{2072}                 & 323.14                       & 13                             
\end{tabular}
\end{table}


\paragraph{Comparison of $A^*$ search heuristics}

For $A^*$-search, we considered three different heuristics:
\begin{enumerate}
	\item The \textbf{pseudo-heuristic "H1"}, which returns constant cost. As such $A^*$-search with H1 is equivalent to UCS and (almost) equivalent to BFS. As we would expect, we see the exact same number of Node Expansions as in UCS and very similar time-performance.
	\item The \textbf{"ignore preconditions"} heuristic considers the action-distance to the goal state by finding a (posssibly inadmissable) path of actions that result in the desired goal, but where actions can be performed even when their preconditions are not fulfilled. As a valid heuristic, it's guaranteed to find an optimal solution (provided existence) and in hour experiments lead to an almost \emph{fourfold} performance increase over H1/UCS\textemdash both terms of node expansions (P2: 1310 vs 4604, P3: 4443 vs 16963) and in time (P2: $4$ vs $14$, P3: $18$ vs $64$ seconds).
	\item The \textbf{PG-Levelsum heuristic} on the other hand, considers each goal literal individually. The minimum level in the planning graph where a single goal literal can be fulfilled is known as its \emph{level cost}. The PG-Levelsum heuristic then returns the sum of the individual level costs.
	Note that the level sum heuristic is technically inadmissible \cite[p. 382]{russell2009artificial}, as it disregards any possible \emph{positive} coupling effects - in this case the possibility to load multiple parcels onto a plane and fly a route that's shorter in total than considering each parcel separately. In fact, while this heuristic found optimal solutions to P1 and P2, its found solution to P3 in our implementation was indeed suboptimal, using 13 instead of 12 planning steps. (Analysis of this path revealed, that a plane indeed went to its final destination to drop off a package, then circled back to another airport to pick up another cargo and returning to its final destination - instead of picking up that package "along the way".) However, it can be said that this heuristic resulted in significantly less node expansions than the other heuristics considered here, in fact another $95\%$ reduction over "ignore preconditions". However, these fewer node expansions did not result in time-performance speedups as constructing and searching the planning graph multiple times for each goal is quite computationally expensive. In fact, we observed on the order of $20X$ the time required as compared to the "ignore preconditions" heuristic.
\end{enumerate}

For detailed results, the reader is again referred to Tables \ref{table-performance1}, \ref{table-performance2} and \ref{table-performance 3}. In conclusion we observe that for this problem class, the "ignore preconditions" heuristic shows the best performance: A considerable speedup vs nonheuristic methods such as BFS/UCS while still yielding optimal solutions. While not the case here, the PG-Levelsum heuristic may be promising, however, for problems where individual node expansions may be very expensive or prohibitive.

% \nocite{*}
%\bibliographystyle{apalike}%amsalpha
\addcontentsline{toc}{chapter}{References} 
\bibliography{references}

\end{document}